{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db53b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "from line_junction_utils import *\n",
    "from robust_line_based_estimator.line_matcher import LineMatcher\n",
    "from robust_line_based_estimator.vp_matcher import vp_matching\n",
    "from robust_line_based_estimator.visualization import plot_images, plot_lines, plot_color_line_matches, plot_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ccbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "matcher_type = \"lbd\" # \"sold2\"\n",
    "dataset_path = \"/media/hdd2tb/datasets/RANSAC-Tutorial-Data/train\"\n",
    "output_path = \".\"\n",
    "threshold = 10 # Threshold in pixels\n",
    "scenes = [ \"buckingham_palace\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc86ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the line matcher\n",
    "if matcher_type == \"lbd\":\n",
    "    # LSD+LBD matcher\n",
    "    matcher = LineMatcher(line_detector='lsd', line_matcher='lbd')\n",
    "else:\n",
    "    # SOLD2 matcher\n",
    "    conf = {\n",
    "        'sold2': {\n",
    "            'ckpt_path': '../third_party/SOLD2/pretrained_models/sold2_wireframe.tar',\n",
    "            'device': 'cpu'\n",
    "        }\n",
    "    }\n",
    "    matcher = LineMatcher(line_detector='sold2', line_matcher='sold2', conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8aa8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processingScene(dataset_path, K1_K2, R, T, matcher, linefile_path, matchfile_path, threshold, visualize=0):\n",
    "    cnt = 0\n",
    "    for k, m in tqdm(K1_K2.items(), disable = visualize > 0):\n",
    "\n",
    "        img_id0 = k.split('-')[0]\n",
    "        img_id1 = k.split('-')[1]\n",
    "\n",
    "        img0 = cv2.imread(f\"{dataset_path}/images/{img_id0}.jpg\", 0)\n",
    "        img1 = cv2.imread(f\"{dataset_path}/images/{img_id1}.jpg\", 0)\n",
    "\n",
    "        ## Detecting line segments in the first image\n",
    "        features0_segments = read_h5(f\"img-{img_id0}-line-segments\", linefile_path)\n",
    "        features0_descs = read_h5(f\"img-{img_id0}-descriptor\", linefile_path)\n",
    "        features0_ms_lines = read_h5(f\"img-{img_id0}-ms_lines\", linefile_path)\n",
    "        if features0_segments is None:\n",
    "            features0 = matcher.detect_and_describe_lines(img0)\n",
    "            append_h5({f\"img-{img_id0}-line-segments\": features0[\"line_segments\"],\n",
    "                f\"img-{img_id0}-descriptor\": features0[\"descriptor\"], \n",
    "                f\"img-{img_id0}-ms_lines\": convert_ms_lines(features0[\"ms_lines\"])}, \n",
    "                linefile_path)\n",
    "        else:\n",
    "            features0 = { \"line_segments\": features0_segments, \n",
    "                \"descriptor\": features0_descs,\n",
    "                \"ms_lines\": parse_ms_lines(features0_ms_lines) }\n",
    "         \n",
    "        # Detecting line segments in the second image\n",
    "        features1_segments = read_h5(f\"img-{img_id1}-line-segments\", linefile_path)\n",
    "        features1_descs = read_h5(f\"img-{img_id1}-descriptor\", linefile_path)\n",
    "        features1_ms_lines = read_h5(f\"img-{img_id1}-ms_lines\", linefile_path)\n",
    "        if features1_segments is None:\n",
    "            features1 = matcher.detect_and_describe_lines(img1)\n",
    "            append_h5({f\"img-{img_id1}-line-segments\": features1[\"line_segments\"],\n",
    "                f\"img-{img_id1}-descriptor\": features1[\"descriptor\"], \n",
    "                f\"img-{img_id1}-ms_lines\": convert_ms_lines(features1[\"ms_lines\"])}, \n",
    "                linefile_path)\n",
    "        else:\n",
    "            features1 = { \"line_segments\": features1_segments, \n",
    "                \"descriptor\": features1_descs,\n",
    "                \"ms_lines\": parse_ms_lines(features1_ms_lines) }\n",
    "\n",
    "        if visualize > 0 and False:\n",
    "            # Display the detections\n",
    "            plot_images([img0, img1], ['Detections 0', 'Detections 1'])\n",
    "            plot_lines([features0[\"line_segments\"][:, :, [1, 0]], features1[\"line_segments\"][:, :, [1, 0]]])\n",
    "\n",
    "        ## Matching\n",
    "        m_lines0 = read_h5(f\"{img_id0}-{img_id1}-m_lines0\", matchfile_path)\n",
    "        m_lines1 = read_h5(f\"{img_id0}-{img_id1}-m_lines1\", matchfile_path)\n",
    "        if m_lines0 is None:\n",
    "            _, m_lines0, m_lines1 = matcher.match_lines(img0, img1, features0, features1)\n",
    "            append_h5({f\"{img_id0}-{img_id1}-m_lines0\": m_lines0,\n",
    "                f\"{img_id0}-{img_id1}-m_lines1\": m_lines1}, \n",
    "                matchfile_path)\n",
    "\n",
    "        # Get all possible line junctions\n",
    "        keypoints1, keypoints2 = get_line_junctions(m_lines0, m_lines1)\n",
    "\n",
    "        # Normalize the obtained keypoints by the camera matrix\n",
    "        K1 = K1_K2[k][0][0]\n",
    "        K2 = K1_K2[k][0][1]\n",
    "        kp1n = normalize_keypoints(keypoints1[:, [1, 0]], K1).astype(np.float64)\n",
    "        kp2n = normalize_keypoints(keypoints2[:, [1, 0]], K2).astype(np.float64)\n",
    "\n",
    "        # Normalizing the threshold by the camera matrices\n",
    "        normalized_threshold = threshold / (0.25 * (K1[0, 0] + K1[1, 1] + K2[0, 0] + K2[1, 1]))\n",
    "\n",
    "        # Composing the projection matrices from the rotations and translations\n",
    "        R1 = R[img_id0].squeeze()\n",
    "        R2 = R[img_id1].squeeze()\n",
    "        T1 = T[img_id0].squeeze()\n",
    "        T2 = T[img_id1].squeeze()\n",
    "\n",
    "        P1 = np.concatenate((R1, np.resize(T1, (3, 1))), axis=1)\n",
    "        P2 = np.concatenate((R2, np.resize(T2, (3, 1))), axis=1)\n",
    "\n",
    "        # Checking each point's consistency with the camera poses by\n",
    "        # triangulating them and, then, calculating the re-projection error.\n",
    "        # for point_idx in range(kp1n.shape[0]):\n",
    "        points3d, status = polynomial_triangulation(kp1n, P1, kp2n, P2)\n",
    "        # s_errors = sampson_errors(keypoints1, keypoints2, K1 @ P1, K2 @ P2)\n",
    "        errors = reprojection_errors(keypoints1[:, [1, 0]], keypoints2[:, [1, 0]], points3d, K1 @ P1, K2 @ P2)\n",
    "\n",
    "        inlier_mask = errors < threshold      \n",
    "\n",
    "        if visualize > 0:\n",
    "            print(f\"Point number = {kp1n.shape[0]}\")    \n",
    "            print(f\"Inlier number = {inlier_mask.sum()}\")\n",
    "\n",
    "            # Select points that fall inside the images\n",
    "            points_inside1 = (keypoints1[:,1] >= 0) & (keypoints1[:,1] < img0.shape[1]) & (keypoints1[:,0] >= 0) & (keypoints1[:,0] < img0.shape[0])\n",
    "            points_inside2 = (keypoints2[:,1] >= 0) & (keypoints2[:,1] < img1.shape[1]) & (keypoints2[:,0] >= 0) & (keypoints2[:,0] < img1.shape[0])\n",
    "            points_inside = points_inside1 & points_inside2 & inlier_mask\n",
    "\n",
    "            # Plot the matches\n",
    "            plot_images([img0, img1], ['Keypoints 0', 'Keypoints 1'])\n",
    "            plot_color_line_matches([m_lines0[:, :, [1, 0]], m_lines1[:, :, [1, 0]]])\n",
    "\n",
    "            tmpKps1 = np.stack((keypoints1[points_inside, 1], keypoints1[points_inside, 0]), axis=1)\n",
    "            tmpKps2 = np.stack((keypoints2[points_inside, 1], keypoints2[points_inside, 0]), axis=1)\n",
    "            plot_matches(tmpKps1, tmpKps2)\n",
    "\n",
    "            cnt += 1\n",
    "            if cnt >= visualize:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d2220",
   "metadata": {},
   "source": [
    "## Line detection and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441231d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K1_K2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1511027/888965495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Iterating through the image pairs in the scene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     processingScene(f'{dataset_path}/{scene}', \n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mK1_K2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K1_K2' is not defined"
     ]
    }
   ],
   "source": [
    "for scene in scenes:\n",
    "    # Loading the camera parameters and the ground truth pose\n",
    "    K1_K2 = load_h5(f'{dataset_path}/{scene}/K1_K2.h5')\n",
    "    R = load_h5(f'{dataset_path}/{scene}/R.h5')\n",
    "    T = load_h5(f'{dataset_path}/{scene}/T.h5')\n",
    "    # Iterating through the image pairs in the scene\n",
    "    processingScene(f'{dataset_path}/{scene}', \n",
    "        K1_K2, \n",
    "        R, \n",
    "        T, \n",
    "        matcher, \n",
    "        f\"{output_path}/lines_{scene}.h5\", \n",
    "        f\"{output_path}/matches_{scene}.h5\", \n",
    "        threshold,\n",
    "        visualize=5)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2328b2900916ebe49871cf7fb418aafb5182e08877aeb0eb3e6317399373126"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
